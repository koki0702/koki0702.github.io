<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="icon" href="../favicon.ico">
  <title>Step 5: Theory of Backpropagation &mdash; DeZero Book  </title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Mono"><link rel="stylesheet" href="../static/typlog.css?v=0.7.3" type="text/css" />
  <link rel="stylesheet" href="../static/theme.css?v=0.7.3" type="text/css" /><link rel="stylesheet" href="../static/copybutton.css" type="text/css" />
      <link rel="index" title="Index" href="../genindex.html"/>
      
    <link rel="top" title="DeZero Book" href="index.html"/>
      <link rel="next" title="Step 6: Backpropagation by hand" href="step06.html"/>
      <link rel="prev" title="Step 4: Numerical Differentiation" href="step04.html"/>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-33864994-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-33864994-1');
</script>
  <script type="text/javascript" id="documentation_options" data-url_root="../" src="../static/documentation_options.js"></script>
    <script src="../static/jquery.js"></script>
    <script src="../static/underscore.js"></script>
    <script src="../static/doctools.js"></script>
    <script src="../static/language_data.js"></script>
    <script src="../static/clipboard.min.js"></script>
    <script src="../static/copybutton.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
  <meta property="og:type" content="website">
  <meta property="og:site_name" content="DeZero Book">
  <meta property="og:title" content="Step 5: Theory of Backpropagation">
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:site" content="@SaitohKoki" />
  <meta property="og:url" content="https://koki0702.github.io/dezero-book/en/step05.html" />
  <meta property="og:image" content="https://koki0702.github.io/dezero-book/images/summary.png" />
</head>
<body role="document" data-page="en/step05">
  <header class="t-head">
    <div class="t-head_menu"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M64 384h384v-42.666H64V384zm0-106.666h384v-42.667H64v42.667zM64 128v42.665h384V128H64z"/></svg></div>
    <a class="t-head_logo" href="index.html">DeZero Book
    </a>
  </header>
  <aside class="t-sidebar">
    <div class="t-sidebar_close">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M405 136.798L375.202 107 256 226.202 136.798 107 107 136.798 226.202 256 107 375.202 136.798 405 256 285.798 375.202 405 405 375.202 285.798 256z"/></svg>
    </div>
    <div class="inner">
<a class="logo" href="index.html">
    DeZero Book
</a>
<div class="github_wrap">
  <a class="github" href="../ja/step05.html">
      日本語
  </a>
  <p class="github_on" href="#">
      English
  </p>
</div><div class="globaltoc">
<p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="step00.html">Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="part01.html">Stage 1: Automatically compute derivatives</a><ul>
<li class="toctree-l1"><a class="reference internal" href="step01.html">Step 1: Variables as boxes</a></li>
<li class="toctree-l1"><a class="reference internal" href="step02.html">Step 2: Function to create a variable</a></li>
<li class="toctree-l1"><a class="reference internal" href="step03.html">Step 3: Connecting Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="step04.html">Step 4: Numerical Differentiation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Step 5: Theory of Backpropagation</a></li>
<li class="toctree-l1"><a class="reference internal" href="step06.html">Step 6: Backpropagation by hand</a></li>
<li class="toctree-l1"><a class="reference internal" href="step07.html">Step 7: Automation of backpropagation</a></li>
<li class="toctree-l1"><a class="reference internal" href="step08.html">Step 8: From Recursion to Loop</a></li>
<li class="toctree-l1"><a class="reference internal" href="step09.html">Step 9: Making Functions More Useful</a></li>
<li class="toctree-l1"><a class="reference internal" href="step10.html">Step 10: Perform the test</a></li>
<li class="toctree-l1"><a class="reference internal" href="column01.html">Column: Automatic Differentiation</a></li>
</ul>
</li></ul>
</div>

    </div>
  </aside>
  <div class="t-content">
    <div class="t-body yue">
      
  <div class="section" id="Step-5:-Theory-of-Backpropagation">
<h1>Step 5: Theory of Backpropagation<a class="headerlink" href="#Step-5:-Theory-of-Backpropagation" title="Permalink to this headline">¶</a></h1>
<p>We were able to find the derivative by numerical differentiation. However, numerical differentiation have had problems in terms of computational cost and accuracy. Backpropagation solves both of those problems! In other words, it is possible to obtain the derivative more efficiently and with a smaller error value. This step does not implement backpropagation, but only explains the theory. Then the next step is to implement backpropagation.</p>
<div class="section" id="5.1-Chain-rule">
<h2>5.1 Chain rule<a class="headerlink" href="#5.1-Chain-rule" title="Permalink to this headline">¶</a></h2>
<p>The key to understanding backpropagation is the <strong>chain rule</strong>. The word “chain” describes how multiple functions are used in a chain. A chain rule indicates that the derivatives of multiple concatenated functions (composite functions) can be “decomposed” into the product of the derivatives of each of their constituent functions.</p>
<p>Let’s explain the chain rule with a concrete example. For example, we have a function <span class="math notranslate nohighlight">\(y=F(x)\)</span>. And suppose that this function <span class="math notranslate nohighlight">\(F\)</span> is composed of three functions, <span class="math notranslate nohighlight">\(a=A(x)\)</span>, <span class="math notranslate nohighlight">\(b=B(a)\)</span>, and <span class="math notranslate nohighlight">\(y=C(b)\)</span>. Incidentally, this function looks like <strong>Figure 5-1</strong> when written as a computational graph.</p>
<p align="center"><img alt="img1-7" src="../images/1-7.png" /></p>
<p align="center"><strong>Figure 5-1</strong> Example of the composite function</p>
<p>In this case, the derivative of <span class="math notranslate nohighlight">\(y\)</span> with respect to <span class="math notranslate nohighlight">\(x\)</span> can be represented by <strong>Figure 5-1</strong>.</p>
<div class="math notranslate nohighlight">
\[\frac{dy}{dx} = \frac{dy}{db} \frac{db}{da} \frac{da}{dx} \tag{5.1}\]</div>
<p>As Equation (5.1) shows, the derivative of <span class="math notranslate nohighlight">\(y\)</span> for <span class="math notranslate nohighlight">\(x\)</span> is represented by the product of the derivative of each function. In other words, the derivative of a composite function can be decomposed into the local derivative of each function. This is the chain rule. In addition, the chain rule represented by equation (5.1) can also be written by explicitly including <span class="math notranslate nohighlight">\(\frac{dy}{dy}\)</span>, as follows</p>
<div class="math notranslate nohighlight">
\[\frac{dy}{dx} = \frac{dy}{dy} \frac{dy}{db} \frac{db}{da} \frac{da}{dx} \tag{5.2}\]</div>
<p><span class="math notranslate nohighlight">\(\frac{dy}{dy}\)</span> is a derivative with respect to “myself” and its value will always be 1. Therefore, it is usual to omit the product of derivatives related to “myself” such as <span class="math notranslate nohighlight">\(\frac{dy}{dy}\)</span>, but we will include it here in anticipation of the implementation of backpropagation.</p>
<div class="admonition note">
<p class="admonition-title">NOTE</p>
<p><span class="math notranslate nohighlight">\(\frac{dy}{dy}\)</span> is a derivative of <span class="math notranslate nohighlight">\(y\)</span> with respect to <span class="math notranslate nohighlight">\(y\)</span>. In this case, if <span class="math notranslate nohighlight">\(y\)</span> changes only a certain small value, then <span class="math notranslate nohighlight">\(y\)</span>, which is itself, also changes by the same amount. Therefore, the rate of change is always <span class="math notranslate nohighlight">\(1\)</span> for any function.</p>
</div>
</div>
<div class="section" id="5.2-Derivation-of-back-propagation">
<h2>5.2 Derivation of back-propagation<a class="headerlink" href="#5.2-Derivation-of-back-propagation" title="Permalink to this headline">¶</a></h2>
<p>Let’s take a closer look at equation (5.2). Equation (5.2) implies that the derivative of the composite function can be decomposed into the product of the derivative of each function. However, it doesn’t specify about “in what order to multiply” it. Of course, you are free to decide on that point. So, let’s consider calculating in order from the output to the input direction, as shown in Equation (5.3).</p>
<div class="math notranslate nohighlight">
\[\frac{dy}{dx} = \biggl(\biggl(\frac{dy}{dy} \frac{dy}{db} \biggl) \frac{db}{da}\biggl) \frac{da}{dx} \tag{5.3}\]</div>
<p>As shown in Equation (5.3), it calculates the derivative from the output to the input - that is, in the opposite direction of the normal calculation. In this case, the flow of the calculation of Equation (5.3) is as shown in <strong>Figure 5-2</strong>.</p>
<p align="center"><img alt="img1-8" src="../images/1-8.png" /></p>
<p align="center"><strong>Figure 5-2</strong> Flow of calculation from the output side derivative</p>
<p>As shown in <strong>Figure 5-2</strong>, compute the derivatives in turn, multiplying from the output <span class="math notranslate nohighlight">\(y\)</span> in the direction of the input <span class="math notranslate nohighlight">\(x\)</span>. By doing so, you will finally get <span class="math notranslate nohighlight">\(\frac{dy}{dx}\)</span>. This calculation can be expressed in a “computational graph” as shown in <strong>Figure 5-3</strong>.</p>
<p align="center"><img alt="img1-9" src="../images/1-9.png" /></p>
<p align="center"><strong>Figure 5-3</strong> Computation graph for <span class="math notranslate nohighlight">\(\frac{dy}{dx}\)</span></p>
<p>Let’s take a closer look at the computational graph in <strong>Figure 5-3</strong>. We start with <span class="math notranslate nohighlight">\(\frac{dy}{dy} (=1)\)</span> and calculate the product of <span class="math notranslate nohighlight">\(\frac{dy}{db}\)</span>. where <span class="math notranslate nohighlight">\(\frac{dy}{db}\)</span> is the derivative of the function <span class="math notranslate nohighlight">\(y=C(b)\)</span>. Therefore, we can write <span class="math notranslate nohighlight">\(C'(b)\)</span> by denoting the derivative of the function <span class="math notranslate nohighlight">\(C\)</span> by <span class="math notranslate nohighlight">\(C'\)</span>, which is <span class="math notranslate nohighlight">\(\frac{dy}{db}=C'(b)\)</span>. Similarly, <span class="math notranslate nohighlight">\(\frac{db}{da}=B'(a)\)</span> and <span class="math notranslate nohighlight">\(\frac{da}{dx}=A'(x)\)</span>. With the above in mind, the computational
graph in <strong>Figure 5-3</strong> can be simplified and written as follows.</p>
<p align="center"><img alt="img1-10" src="../images/1-10.png" /></p>
<p align="center"><strong>Figure 5-4</strong> Computational graph of simplified inverse propagation (multiplication of <span class="math notranslate nohighlight">\(A'(x)\)</span> is simplified and represented by a node named “<span class="math notranslate nohighlight">\(A'(x)\)</span>”)</p>
<p>As shown in** Figure 5-4<a href="#id1"><span class="problematic" id="id2">**</span></a>, we will represent the product of a derivative as a single function node. This will make the flow of the derivative clearer. If you look at <a href="#id3"><span class="problematic" id="id4">**</span></a>Figure 5-4**, you can see that the “derivative for each variable of <span class="math notranslate nohighlight">\(y\)</span>” propagates from right to left. This is reverse propagation. The important point here is that the data being propagated is all “derivatives of <span class="math notranslate nohighlight">\(y\)</span>”. To be specific, we can see that <span class="math notranslate nohighlight">\(\frac{dy}{dy}\)</span>, <span class="math notranslate nohighlight">\(\frac{dy}{db}\)</span>,
<span class="math notranslate nohighlight">\(\frac{dy}{da}\)</span>, and <span class="math notranslate nohighlight">\(\frac{dy}{dx}\)</span> are all propagated by “the derivative of <span class="math notranslate nohighlight">\(y\)</span> on the xxx”.</p>
<div class="admonition note">
<p class="admonition-title">NOTE</p>
<p>The reason for specifying the order of computation from the output to the input direction, as in Equation (5.3), is to propagate the derivative of <span class="math notranslate nohighlight">\(y\)</span>. In other words, to treat <span class="math notranslate nohighlight">\(y\)</span> as an “important person”. If we were to do the calculations in order from input to output direction, the input, <span class="math notranslate nohighlight">\(x\)</span>, would be the “important person”. In that case, the propagating derivative would be <span class="math notranslate nohighlight">\(\frac{dx}{dx}\)</span> → <span class="math notranslate nohighlight">\(\frac{da}{dx}\)</span> → <span class="math notranslate nohighlight">\(\frac{db}{dx}\)</span> → <span class="math notranslate nohighlight">\(\frac{dy}{dx}\)</span>, and
the derivative about <span class="math notranslate nohighlight">\(x\)</span> would be propagated. You could also put brackets in such a way that the calculation is sequential from input to output direction. The method based on it is called “automatic differentiation in forward mode”. Automatic differentiation in forward mode is described in the “Column: Automatic Differentiation” section of this book.</p>
</div>
<p>Many problems in machine learning can be formulated with a large number of parameters as inputs and a “loss function” as the final output. The output of this loss function is (in many cases) a single scalar value, which is the “key person”. In other words, we need to find the derivative for each parameter of the loss function. In such cases, if you propagate the derivative from the output to the input direction, you can get the derivative for all the parameters with only one propagation. Because
of this computational efficiency, a method to propagate the derivative in the opposite direction is used.</p>
</div>
<div class="section" id="5.3-Represent-in-a-computational-graph">
<h2>5.3 Represent in a computational graph<a class="headerlink" href="#5.3-Represent-in-a-computational-graph" title="Permalink to this headline">¶</a></h2>
<p>Now, let’s write the normal calculation graph for forward propagation (<strong>Figure 5-1</strong>) and the calculation graph for reverse propagation (<strong>Figure 5-4</strong>), which calculates the derivative, side by side. </p>
<p  align="center"><img alt="img1-11" src="../images/1-111.png" /></p>
<p align="center"><strong>Figure 5-5</strong> Forward propagation (top figure) and reverse propagation (bottom figure)</p>
<p>Looking at <strong>Figure 5-5</strong>, we can see that there is a clear correspondence between forward and backward propagation. For example, the variable <span class="math notranslate nohighlight">\(a\)</span> in forward propagation corresponds to the derivative <span class="math notranslate nohighlight">\(\frac{dy}{da}\)</span> in backward propagation. Similarly, <span class="math notranslate nohighlight">\(b\)</span> and <span class="math notranslate nohighlight">\(\frac{dy}{db}\)</span> correspond, and <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(\frac{dy}{dx}\)</span> correspond. We can also see that there is a correspondence between the functions. For example, the back propagation of the function <span class="math notranslate nohighlight">\(B\)</span>
corresponds to <span class="math notranslate nohighlight">\(B'(a)\)</span>, and <span class="math notranslate nohighlight">\(A\)</span> corresponds to <span class="math notranslate nohighlight">\(A'(x)\)</span>. For example, the back propagation of the function <span class="math notranslate nohighlight">\(B\)</span> corresponds to <span class="math notranslate nohighlight">\(B'(a)\)</span>, and <span class="math notranslate nohighlight">\(A\)</span> corresponds to <span class="math notranslate nohighlight">\(A'(x)\)</span>. Thus, variables have “normal values” and “derivative values” and functions have “normal calculations (forward propagation)” and “calculations to find the differential (backward propagation)”. That way, you can see the prospect of backpropagation.</p>
<p>Finally, let’s look at the function node of <span class="math notranslate nohighlight">\(C'(b)\)</span> in <strong>Figure 5-5</strong>. This is a derivative of the calculation <span class="math notranslate nohighlight">\(y=C(b)\)</span>, but it should be noted here that to calculate <span class="math notranslate nohighlight">\(C'(b)\)</span>, we need a value of <span class="math notranslate nohighlight">\(b\)</span>. Similarly, to find <span class="math notranslate nohighlight">\(B'(a)\)</span>, we need the value of the input <span class="math notranslate nohighlight">\(a\)</span>. What this means is that in the case of back propagation, the data used in the forward propagation will be needed prior to it. Therefore, the backpropagation implementation must first perform forward
propagation and remember the value of the variable from which each function was entered–<span class="math notranslate nohighlight">\(x\)</span>, <span class="math notranslate nohighlight">\(a\)</span>, and <span class="math notranslate nohighlight">\(b\)</span> in the example above. You can then calculate the back propagation of each function.</p>
<p>This is the explanation of backpropagation. It may seem somewhat complicated, but this is one of the most difficult places in the book. There may still be points that don’t add up, but you’ll get a better understanding by actually putting them into action. The next step is to implement backpropagation and verify it by actually running it.</p>
</div>
</div>

  <div class="t-pagination clearfix">
    <span>
      ← <a href="step04.html" title="Step 4: Numerical Differentiation">Step 4: Numerical Differentiation</a>
    </span>
    <span style="float:right">
      <a href="step06.html" title="Step 6: Backpropagation by hand">Step 6: Backpropagation by hand</a> →
    </span>
  </div>

    </div><footer class="t-foot">
    &copy; Copyright 2020, Koki Saitoh.
    <br>
    A <a href="https://typlog.com/">typlog</a> <a href="https://github.com/typlog/sphinx-typlog-theme">sphinx theme</a>,
    designed by <a href="https://lepture.com/">Hsiaoming Yang</a>.
</footer>
  </div>
  <script>$(function(){$(".t-head_menu").on("click",function(){$("body").addClass("_expand")});$(".t-body").on("click",function(){$("body").removeClass("_expand")});$(".t-sidebar_close").on("click",function(){$("body").removeClass("_expand")});$("a.footnote-reference").on("click",function(e){e.preventDefault();var id=$(this).attr("href");var html=$(id).find("td.label + td").html();var w=Math.max(document.documentElement.clientWidth,window.innerWidth||0);var style="top:"+e.pageY+"px;";if(w>560){style+="width:480px;";if(e.pageX>240&&e.pageX+240<w){style+="left:"+(e.pageX-240)+"px;"}else if(e.pageX<=240){style+="left:20px;"}else{style+="right:20px;"}}showFootnote(html,style)});function showFootnote(html,style){var CONTENT_ID="typlog-footnote-content";var content=document.getElementById(CONTENT_ID);if(!content){content=document.createElement("div");content.id=CONTENT_ID;$(".t-body").append(content)}var MASK_ID="typlog-footnote-mask";var mask=document.getElementById(MASK_ID);if(!mask){mask=document.createElement("div");mask.id=MASK_ID;document.body.appendChild(mask);mask.addEventListener("click",function(){content.className="";mask.className=""})}content.innerHTML=html;content.setAttribute("style",style);content.className="_active";mask.className="_active"}function fetchGitHubRepo(repo){var url="https://api.github.com/repos/"+repo;$.getJSON(url,function(data){var counts=[+new Date,data.stargazers_count,data.forks_count];localStorage.setItem("gh:"+repo,JSON.stringify(counts));updateGitHubStats(counts[1],counts[2])})}function updateGitHubStats(stars,forks){$(".github_stars strong").text(stars);$(".github_forks strong").text(forks)}function initGitHub(url){if(!url){return}var repo=url.replace("https://github.com/","");var cache=localStorage.getItem("gh:"+repo);if(cache){try{var counts=JSON.parse(cache);updateGitHubStats(counts[1],counts[2]);var delta=new Date-counts[0];if(delta<0||delta>9e5){fetchGitHubRepo(repo)}}catch(error){fetchGitHubRepo(repo)}}else{fetchGitHubRepo(repo)}}initGitHub($(".github").attr("href"))});</script>
</body>
</html>